CFT Exec Report
Product,Lyve Rack
Build,#Build
Date,Date
System,System

Reported Bugs
Priority,Test Setup,Cortx Stack
Total,21,22
Blocker,31,32
Critical,41,42
Major,51,52
Minor,61,62,
Trivial,71,72

Overall QA Report
Status,#Build,#Build-1
Total,21,22
Pass,31,32
Failed,41,42
Aborted,51,52
Pass,61,62
ToDo,71,72

Component Level Summary
Component,12345,NA,NA,NA
Automation,0,NA,NA,NA
CSM,1,NA,NA,NA
CFT,0,NA,NA,NA
doc,0,NA,NA,NA
Foundation,0,NA,NA,NA
HA,0,NA,NA,NA
hare,0,NA,NA,NA
Monitor,0,NA,NA,NA
Motr,0,NA,NA,NA
Provisioner,0,NA,NA,NA
S3Server,1,NA,NA,NA
UDX,0,NA,NA,NA

Single Bucket Performance Statistics (Average) using S3Bench
Statistics,4 KB,100 KB,1 MB,5 MB,36 MB,64 MB,128 MB,256 MB
Write Throughput (MBps),1,2,3,4,5,6,7,8
Read Throughput (MBps),1,2,3,4,5,6,7,8
Write Latency (ms),1,2,3,4,5,6,7,8,
Read Latency (ms),1,2,3,4,5,6,7,8
Write IOPS,1,2,3,4,5,6,7,8,
Read IOPS,1,2,3,4,5,6,7,8,
Write TTFB (ms),1,2,3,4,5,6,7,8
Read TTFB (ms),1,2,3,4,5,6,7,8

Multiple Buckets Performance Statistics (Average) using HSBench and COSBench
Bench,Statistics,4 KB,100 KB,1 MB,5 MB,36 MB,64 MB,128 MB,256 MB
,Write Throughput,0,6,50,475,1625,2100,2225,2375
HSbench,Read Throughput,2,50,550,1625,4225,4225,4025,4475
1 Bucket,write Latency,1000,1525,1600,925,2125,2875,5425,10375
1000 Objects,Read Latency,175,200,175,300,825,1425,2900,3650
100 Sessions,Write IOPS,100,75,50,100,50,25,17,9
,Read IOPS,550,450,550,325,125,75,25,17,
,Write Throughput,0,5,50,475,1700,2100,2450,2450
HSbench,Read Throughput,2,50,600,1750,4100,4100,4150,4050
10 Buckets,Read Latency,1075,1625,1625,975,2000,2875,5025,10025
100 Objects,write Latency,175,200,150,275,850,1475,2850,3825
100 Sessions,Write IOPS,75,50,50,100,50,25,19,9
,Read IOPS,525,475,600,350,125,75,25,15
,Write Throughput,0,6,50,525,1750,2150,2375,2425
HSbench,Read Throughput,2,50,500,1475,4200,4150,3850,3650
50 Buckets,Read Latency,1000,1500,1625,925,2025,2925,5325,10525
100 Objects,write Latency,175,225,200,350,850,1525,3275,3750
100 Sessions,Write IOPS,100,75,50,100,50,25,18,9
,Read IOPS,600,425,500,300,125,75,25,14,
,Write Throughput,0,8,75,350,500,525,600,725
COSbench,Read Throughput,0,8,75,350,475,525,625,725
1 Bucket,Read Latency,1000,950,950,1075,5925,9675,16475,27175
1000 Objects,Write Latency,250,250,250,350,1425,2400,4475,7650
100 Sessions,Write IOPS,75,75,75,75,13,8,4,2
,Read IOPS,75,75,75,75,13,8,4,2
,Write Throughput,0,8,75,350,475,525,600,725
COSbench,Read Throughput,0,8,75,350,475,550,600,750
10 Buckets,Read Latency,1000,950,975,1100,6125,9900,17625,27625
100 Objects,Write Latency,250,250,250,350,1325,2150,3725,6975
100 Sessions,Write IOPS,75,75,75,75,13,8,4,2
,Read IOPS,75,75,75,75,13,8,4,2
,Write Throughput,0,8,75,325,575,675,825,1025,
COSbench,Read Throughput,0,8,75,325,575,650,850,1100
50 Buckets,Read Latency,1025,950,1000,1150,5025,7675,11625,17675
100 Objects,Write Latency,225,250,250,350,1225,1950,3675,6675
100 Sessions,Write IOPS,75,75,75,75,16,10,6,4
,Read IOPS,75,75,75,75,15,10,6,4

Metadata Latencies (captured with 1KB object)
Operation Latency (ms),Response Time
Add / Edit Object Tags,338.0
Read Object Tags,73.0
Read Object Metadata,73.0,

Timing Summary (Seconds)
Parameters,515,463,403,398,394
Update,1440.0,NA,NA,NA,NA
Deployment,5220.0,NA,5400.0,NA,NA
Boxing,240.0,NA,NA,NA,NA
Unboxing,1380.0,NA,NA,NA,NA,
Onboarding,NA,NA,240.0,NA,NA
Firmware Update,NA,NA,NA,NA,NA
Reboot Node,278.0,NA,345.0,NA,NA
Start Node,NA,NA,NA,NA,NA
Stop Node,NA,NA,10.0,NA,NA
Stop all Services,170.0,NA,167.0,NA,NA
Node Failover,180.0,NA,183.0,NA,NA
Node Failback,160.0,NA,205.0,NA,NA
Start All Services,196.0,NA,205.0,NA,NA
Bucket Creation,1.0,NA,1.0,NA,NA
Bucket Deletion,5.0,NA,4.0,NA,NA

Detailed Reported Bugs,
Component,Test ID,Priority,JIRA ID,Status,Description
CFT_NEW_TEST,TEST-13558,Blocker,EOS-13330,In Progress,HA : Node fail-over is taking more than 120 secs to able to do IO's
CFT_NEW_TEST,TEST-13558,Major,EOS-15384,In Progress,Build #515: Hax crash observed during all SAS phy disable/enable test
CFT_NEW_TEST,TEST-13558,Major,EOS-15355,In Progress,Build: 516 - Isolated Network - S3Server Crash is observed when we recover from node failover
RAS,TEST-5343,Critical,EOS-14711,In Progress,Older MDRAID Alerts getting overwritten On UI with new MDRAID Alerts
RAS,TEST-11083,Blocker,EOS-15280,In Progress,HA : # 486: Stonith resulted after public data cable fault for primary node
CSM,TEST-12845,Blocker,EOS-15306,Closed,Logs :#515: Motr support bundle not collected from support bundle
Provisioner,TEST-9059,Blocker,EOS-15324,Resolved,Install : #515: Boxing process hung blocking shutdown nodes,
CFT_NEW_TEST,TEST-14347,Major,EOS-15336,In Progress,DR : service failed to recover on node-1-m0d@0x7200000000000001:0xc.service
CSM,TEST-12846,Major,EOS-15350,In Progress,Stopping Node-2 services causes the node-1 to shutdown
CFT_NEW_TEST,TEST-14990,Major,EOS-15390,In Progress,Build 515: No alerts observed for enclosure disk disable/enable and enclosure fan removal/insertion operations
CSM,TEST-6150,Major,EOS-15443,New,Firmware upgrade status shows FAIL on UI even if it is passed on controller

